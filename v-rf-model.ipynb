{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-12T14:32:45.558596Z",
     "iopub.status.busy": "2020-10-12T14:32:45.557541Z",
     "iopub.status.idle": "2020-10-12T14:32:45.563668Z",
     "shell.execute_reply": "2020-10-12T14:32:45.564423Z"
    },
    "papermill": {
     "duration": 0.029635,
     "end_time": "2020-10-12T14:32:45.564664",
     "exception": false,
     "start_time": "2020-10-12T14:32:45.535029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/costa-rican-household-poverty-prediction/test.csv.zip\n",
      "/kaggle/input/costa-rican-household-poverty-prediction/sample_submission.csv\n",
      "/kaggle/input/costa-rican-household-poverty-prediction/test.csv\n",
      "/kaggle/input/costa-rican-household-poverty-prediction/train.csv.zip\n",
      "/kaggle/input/costa-rican-household-poverty-prediction/codebook.csv\n",
      "/kaggle/input/costa-rican-household-poverty-prediction/train.csv\n",
      "/kaggle/input/costa-rican-household-poverty-prediction/sample_submission.csv.zip\n",
      "/kaggle/input/costa-rican-household-poverty-prediction/codebook.xlsx\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "#import numpy as np # linear algebra\n",
    "#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014347,
     "end_time": "2020-10-12T14:32:45.595096",
     "exception": false,
     "start_time": "2020-10-12T14:32:45.580749",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-10-12T14:32:45.634111Z",
     "iopub.status.busy": "2020-10-12T14:32:45.633248Z",
     "iopub.status.idle": "2020-10-12T14:32:47.773534Z",
     "shell.execute_reply": "2020-10-12T14:32:47.772746Z"
    },
    "papermill": {
     "duration": 2.163847,
     "end_time": "2020-10-12T14:32:47.773660",
     "exception": false,
     "start_time": "2020-10-12T14:32:45.609813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt # we only need pyplot\n",
    "import matplotlib.cm as cm\n",
    "#sb.set() # set the default Seaborn style for graphics\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T14:32:47.809937Z",
     "iopub.status.busy": "2020-10-12T14:32:47.808831Z",
     "iopub.status.idle": "2020-10-12T14:32:47.812270Z",
     "shell.execute_reply": "2020-10-12T14:32:47.811545Z"
    },
    "papermill": {
     "duration": 0.022934,
     "end_time": "2020-10-12T14:32:47.812400",
     "exception": false,
     "start_time": "2020-10-12T14:32:47.789466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T14:32:47.851942Z",
     "iopub.status.busy": "2020-10-12T14:32:47.851145Z",
     "iopub.status.idle": "2020-10-12T14:32:48.050269Z",
     "shell.execute_reply": "2020-10-12T14:32:48.050997Z"
    },
    "papermill": {
     "duration": 0.223506,
     "end_time": "2020-10-12T14:32:48.051229",
     "exception": false,
     "start_time": "2020-10-12T14:32:47.827723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/train.csv')\n",
    "# Drop target data\n",
    "train_target = train_data['Target']\n",
    "train_data.drop(['Target'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T14:32:48.121742Z",
     "iopub.status.busy": "2020-10-12T14:32:48.115280Z",
     "iopub.status.idle": "2020-10-12T14:32:48.138456Z",
     "shell.execute_reply": "2020-10-12T14:32:48.139088Z"
    },
    "papermill": {
     "duration": 0.068446,
     "end_time": "2020-10-12T14:32:48.139251",
     "exception": false,
     "start_time": "2020-10-12T14:32:48.070805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>v2a1</th>\n",
       "      <th>hacdor</th>\n",
       "      <th>rooms</th>\n",
       "      <th>hacapo</th>\n",
       "      <th>v14a</th>\n",
       "      <th>refrig</th>\n",
       "      <th>v18q</th>\n",
       "      <th>v18q1</th>\n",
       "      <th>r4h1</th>\n",
       "      <th>...</th>\n",
       "      <th>age</th>\n",
       "      <th>SQBescolari</th>\n",
       "      <th>SQBage</th>\n",
       "      <th>SQBhogar_total</th>\n",
       "      <th>SQBedjefe</th>\n",
       "      <th>SQBhogar_nin</th>\n",
       "      <th>SQBovercrowding</th>\n",
       "      <th>SQBdependency</th>\n",
       "      <th>SQBmeaned</th>\n",
       "      <th>agesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_279628684</td>\n",
       "      <td>190000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>100</td>\n",
       "      <td>1849</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_f29eb3ddd</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>144</td>\n",
       "      <td>4489</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>4489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_68de51c94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>121</td>\n",
       "      <td>8464</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>8464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_d671db89c</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>81</td>\n",
       "      <td>289</td>\n",
       "      <td>16</td>\n",
       "      <td>121</td>\n",
       "      <td>4</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_d56d6f5f5</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>121</td>\n",
       "      <td>1369</td>\n",
       "      <td>16</td>\n",
       "      <td>121</td>\n",
       "      <td>4</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id      v2a1  hacdor  rooms  hacapo  v14a  refrig  v18q  v18q1  \\\n",
       "0  ID_279628684  190000.0       0      3       0     1       1     0    NaN   \n",
       "1  ID_f29eb3ddd  135000.0       0      4       0     1       1     1    1.0   \n",
       "2  ID_68de51c94       NaN       0      8       0     1       1     0    NaN   \n",
       "3  ID_d671db89c  180000.0       0      5       0     1       1     1    1.0   \n",
       "4  ID_d56d6f5f5  180000.0       0      5       0     1       1     1    1.0   \n",
       "\n",
       "   r4h1  ...  age  SQBescolari  SQBage  SQBhogar_total  SQBedjefe  \\\n",
       "0     0  ...   43          100    1849               1        100   \n",
       "1     0  ...   67          144    4489               1        144   \n",
       "2     0  ...   92          121    8464               1          0   \n",
       "3     0  ...   17           81     289              16        121   \n",
       "4     0  ...   37          121    1369              16        121   \n",
       "\n",
       "   SQBhogar_nin  SQBovercrowding  SQBdependency  SQBmeaned  agesq  \n",
       "0             0         1.000000            0.0      100.0   1849  \n",
       "1             0         1.000000           64.0      144.0   4489  \n",
       "2             0         0.250000           64.0      121.0   8464  \n",
       "3             4         1.777778            1.0      121.0    289  \n",
       "4             4         1.777778            1.0      121.0   1369  \n",
       "\n",
       "[5 rows x 142 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022508,
     "end_time": "2020-10-12T14:32:48.179957",
     "exception": false,
     "start_time": "2020-10-12T14:32:48.157449",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Feature Engineering based on Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T14:32:48.260950Z",
     "iopub.status.busy": "2020-10-12T14:32:48.241280Z",
     "iopub.status.idle": "2020-10-12T14:32:48.265187Z",
     "shell.execute_reply": "2020-10-12T14:32:48.265989Z"
    },
    "papermill": {
     "duration": 0.067793,
     "end_time": "2020-10-12T14:32:48.266215",
     "exception": false,
     "start_time": "2020-10-12T14:32:48.198422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check columns with nan values and their nan values counts - missing data\n",
    "def findNanCol(orig_df,print_flag=False):\n",
    "    df_missing = orig_df.isnull()\n",
    "    col_list_missing_data = []\n",
    "    for col in df_missing.columns.values.tolist():\n",
    "        try:\n",
    "            x=df_missing[col].value_counts()[1]\n",
    "            if print_flag:\n",
    "                print(\"Column {}: {} missing value counts\".format(col,x))\n",
    "            col_list_missing_data.append(col)\n",
    "        except:\n",
    "            continue\n",
    "    return col_list_missing_data\n",
    "\n",
    "\n",
    "# Get all col with type Objects to check if there more than one type and for labelencoder\n",
    "def findObjectTypeCol(orig_df,print_flag=False):\n",
    "    obj_col_list = []\n",
    "    for col in orig_df.columns.values.tolist():\n",
    "        if orig_df[col].dtypes == \"object\":\n",
    "            if print_flag:\n",
    "                print(col)\n",
    "            obj_col_list.append(col)\n",
    "    return obj_col_list\n",
    "\n",
    "# Fill NA values in dataset appropriately\n",
    "def fillMissingValues(train_data):\n",
    "    \n",
    "    # Fill the nans in v2a1 with 0s as most have paid for their own house and thus no rent payment.\n",
    "    train_data['v2a1'] = train_data['v2a1'].fillna(0).astype('float64')\n",
    "    \n",
    "    # Fill nan with 0s as only v18q with 0s have nan values for v18q1\n",
    "    # Furthermore, we will get the avg num of laptops per household member which is a better feature.\n",
    "    # The new feature will be created in 3rd stage of feature engineering.\n",
    "    train_data['v18q1'] = train_data['v18q1'].fillna(0).astype('float64')\n",
    "    \n",
    "    # Fill nans in rez_esc with zeros as this feature is meant for age between 7 and 19 as per definition.\n",
    "    train_data['rez_esc'] = train_data['rez_esc'].fillna(0).astype('float64')\n",
    "    \n",
    "    # It turns out that the number of household members 18+ is zero which have givesn the nan value.\n",
    "    # Therefore, we will convert \"meanedu\" values to zero.\n",
    "    train_data['meaneduc'] = train_data['meaneduc'].fillna(0).astype('float64')\n",
    "    train_data['SQBmeaned'] = train_data['SQBmeaned'].fillna(0).astype('float64')\n",
    "    \n",
    "    return train_data\n",
    "\n",
    "# Calculate depenedncy rate for those missing values\n",
    "def getDependencyRate(train_data):\n",
    "    for i,val in enumerate(train_data['dependency']):\n",
    "        if val == 'no':\n",
    "            train_data.loc[i,'dependency'] = 0\n",
    "        elif val == 'yes':\n",
    "            total_num = float(train_data.loc[i,'hogar_total'])\n",
    "            num_abv_65_and_below_19 = float(train_data.loc[i,'hogar_nin']) + float(train_data.loc[i,'hogar_mayor'])\n",
    "            train_data.loc[i,'dependency'] = num_abv_65_and_below_19/(total_num - num_abv_65_and_below_19)\n",
    "\n",
    "    train_data['dependency'] = train_data['dependency'].astype('float64')\n",
    "    return train_data\n",
    "\n",
    "# Encodes features with more than one data type\n",
    "def encoder(train_data):\n",
    "    dic = {'yes' : '1', 'no' : '0'}\n",
    "    \n",
    "    train_data.drop(['Id'],axis=1,inplace=True)\n",
    "    train_data['idhogar'] = LabelEncoder().fit_transform(train_data['idhogar'])\n",
    "    train_data = getDependencyRate(train_data)\n",
    "    train_data['edjefe']= train_data['edjefe'].replace(dic).astype('float64')\n",
    "    train_data['edjefa'] = train_data['edjefa'].replace(dic).astype('float64')\n",
    "    \n",
    "    return train_data\n",
    "\n",
    "# Converts str type columns to float\n",
    "def convertToFloat(train_data,obj_col_list,col_list_missing_data):\n",
    "    obj_col_list.extend(col_list_missing_data)\n",
    "    for col in train_data.columns.values.tolist():\n",
    "        if col not in obj_col_list:\n",
    "            train_data[col] = train_data[col].astype('float64')\n",
    "    return train_data\n",
    "\n",
    "# Adds and modifies new features\n",
    "def addAndModifyFeatures(train_data):\n",
    "    ### Definition:\n",
    "    # r4t3: Total number of individuals in houshold including domestic employees/friends/tenants.\n",
    "    # hogar_total = tamgog = hhsize: Total number of houshold members excluding domestic employees/friends/tenants.\n",
    "    # tamviv: Unclear definition so will be dropped.\n",
    "    \n",
    "    ### Add new features\n",
    "    \n",
    "    train_data['v2a1_per_room'] = train_data['v2a1']/train_data['rooms']\n",
    "    # It is logical for a household to account only for tables among household members.\n",
    "    train_data['v18q1_per_household_member'] = train_data['v18q1']/train_data['hogar_total']\n",
    "    # It is logical for a household to account only for mobile phones among household members.\n",
    "    train_data['qmobileph_per_household_member'] = train_data['qmobilephone']/train_data['hogar_total']\n",
    "    # It is logical for a household to account only for rooms among household members. Having non\n",
    "    # household members to stay is subjective and not considered as essentials.\n",
    "    train_data['rooms_per_household_member'] = train_data['rooms']/train_data['hogar_total']\n",
    "     # It is logical for a household to account only for bedrooms among household members. Having non\n",
    "    # household members to stay is subjective and not considered as essentials.\n",
    "    train_data['bedroom_per_household_member'] = train_data['bedrooms']/train_data['hogar_total']\n",
    "    # Number of non household members in the house(domestic employees/friends/tenants)\n",
    "    train_data['Num_of_non_household_members'] = train_data['r4t3']-train_data['hogar_total']\n",
    "    # Proportion of household adults aged btw 19 and 65 ---> (adults-old_aged)/total\n",
    "    train_data['hogar_adul_btw_19_and_65'] = (train_data['hogar_adul']-train_data['hogar_mayor'])/train_data['hogar_total']\n",
    "    \n",
    "    \n",
    "    ### Modify to obtain proportion features\n",
    "    \n",
    "    # The feature values below includes non houshold mmbers as mentioned in data exploration notebook.\n",
    "    # Therefore, the values are divided by total number of people in house.\n",
    "    train_data['r4h1'] = train_data['r4h1']/train_data['r4t3']\n",
    "    train_data['r4h2'] = train_data['r4h2']/train_data['r4t3']\n",
    "    train_data['r4h3'] = train_data['r4h3']/train_data['r4t3']\n",
    "    train_data['r4m1'] = train_data['r4m1']/train_data['r4t3']\n",
    "    train_data['r4m2'] = train_data['r4m2']/train_data['r4t3']\n",
    "    train_data['r4m3'] = train_data['r4m3']/train_data['r4t3']\n",
    "    train_data['r4t1'] = train_data['r4t1']/train_data['r4t3']\n",
    "    train_data['r4t2'] = train_data['r4t2']/train_data['r4t3']\n",
    "\n",
    "    # The feature values below excludes non houshold mmbers as verified in data exploration notebook.\n",
    "    # Therefore, the values are divided by number of houehold members.\n",
    "    train_data['hogar_nin'] = train_data['hogar_nin']/train_data['hogar_total']\n",
    "    train_data['hogar_adul'] = train_data['hogar_adul']/train_data['hogar_total']\n",
    "    train_data['hogar_mayor'] = train_data['hogar_mayor']/train_data['hogar_total'] \n",
    "    \n",
    "    ### Remove feature col as some are duplicates and \n",
    "    # most of these col are total number which is included in proportion calculation\n",
    "    train_data.drop(['idhogar','v18q1','rooms','bedrooms','r4t3','hogar_total','agesq','hhsize','tamviv','tamhog'],axis=1,inplace=True)\n",
    "    \n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T14:32:48.329360Z",
     "iopub.status.busy": "2020-10-12T14:32:48.324060Z",
     "iopub.status.idle": "2020-10-12T14:32:48.338309Z",
     "shell.execute_reply": "2020-10-12T14:32:48.339302Z"
    },
    "papermill": {
     "duration": 0.051156,
     "end_time": "2020-10-12T14:32:48.339488",
     "exception": false,
     "start_time": "2020-10-12T14:32:48.288332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Applies feature engineering in one function\n",
    "def applyFE(train_data):\n",
    "    # List of columns that have missing values and their corresponding number of missing value counts\n",
    "    col_list_missing_data = findNanCol(train_data)\n",
    "    \n",
    "    # List of columns that needs to be verified as they in object type\n",
    "    obj_col_list = findObjectTypeCol(train_data)\n",
    "    \n",
    "    # Convert columns not having missing data or not having many object types to float\n",
    "    train_data = convertToFloat(train_data,obj_col_list,col_list_missing_data)\n",
    "    \n",
    "    ### STAGE 1\n",
    "    ### Dealing with features with missing values.\n",
    "    # Fills missing values\n",
    "    train_data = fillMissingValues(train_data)\n",
    "    \n",
    "    ### STAGE 2\n",
    "    ### Dealing with features with object types.\n",
    "    # Encodes features with more than one data type\n",
    "    train_data = encoder(train_data)\n",
    "    \n",
    "    ### STAGE 3\n",
    "    ### Dealing with new and modified features.\n",
    "    # Encodes features with more than one data type\n",
    "    train_data = addAndModifyFeatures(train_data)\n",
    "    \n",
    "    return train_data\n",
    "\n",
    "# Get components of predicted labels\n",
    "def getConstituentsOfPredicted(cf,pred_label,angle=45):\n",
    "\n",
    "    # cf[actual-1][predicted-1]\n",
    "    p13 = cf[0][pred_label-1]\n",
    "    p23 = cf[1][pred_label-1]\n",
    "    p33 = cf[2][pred_label-1]\n",
    "    p43 = cf[3][pred_label-1]\n",
    "\n",
    "    # Data to plot\n",
    "    pred_labels = ['extreme poverty', 'moderate poverty', 'vulnerable households','non vulnerable households']\n",
    "    sizes = [p13, p23, p33, p43]\n",
    "    colors = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue']\n",
    "\n",
    "    # Plot\n",
    "    plt.pie(sizes, labels=pred_labels, colors=colors, autopct='%1.0f%%', shadow=False, startangle=angle, textprops={'fontsize': 14})\n",
    "    plt.title(\"Constituents of Costa Rican Household Poverty Levels predicted as \"+pred_labels[pred_label-1],fontsize=20)\n",
    "\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "    \n",
    "    return p13,p23,p33,p43\n",
    "\n",
    "# Get components of actual labels\n",
    "def getPredictionOfActualLabels(p,cf,actual_label,angle=45):\n",
    "    \n",
    "    # Data to plot\n",
    "    labels = ['extreme poverty', 'moderate poverty', 'vulnerable households','non vulnerable households']\n",
    "    sizes = [p[0], p[1], p[2], p[3]]\n",
    "    colors = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue']\n",
    "\n",
    "    # Plot\n",
    "    plt.pie(sizes, labels=labels, colors=colors, autopct='%1.0f%%', shadow=False, startangle=angle, textprops={'fontsize': 14})\n",
    "    plt.title(\"Predictions of Costa Rican Household Poverty Levels with actual labels as \"+labels[actual_label-1],fontsize=20)\n",
    "\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T14:32:48.385720Z",
     "iopub.status.busy": "2020-10-12T14:32:48.384840Z",
     "iopub.status.idle": "2020-10-12T14:32:50.842650Z",
     "shell.execute_reply": "2020-10-12T14:32:50.841971Z"
    },
    "papermill": {
     "duration": 2.486474,
     "end_time": "2020-10-12T14:32:50.842783",
     "exception": false,
     "start_time": "2020-10-12T14:32:48.356309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature Engineering for train data\n",
    "train_data = applyFE(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T14:32:50.881996Z",
     "iopub.status.busy": "2020-10-12T14:32:50.881223Z",
     "iopub.status.idle": "2020-10-12T14:32:50.888249Z",
     "shell.execute_reply": "2020-10-12T14:32:50.887508Z"
    },
    "papermill": {
     "duration": 0.028687,
     "end_time": "2020-10-12T14:32:50.888375",
     "exception": false,
     "start_time": "2020-10-12T14:32:50.859688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = train_data.copy()\n",
    "y_train = train_target.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016481,
     "end_time": "2020-10-12T14:32:50.921826",
     "exception": false,
     "start_time": "2020-10-12T14:32:50.905345",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Model: RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T14:32:50.965239Z",
     "iopub.status.busy": "2020-10-12T14:32:50.963570Z",
     "iopub.status.idle": "2020-10-12T14:33:10.742762Z",
     "shell.execute_reply": "2020-10-12T14:33:10.742180Z"
    },
    "papermill": {
     "duration": 19.804232,
     "end_time": "2020-10-12T14:33:10.742909",
     "exception": false,
     "start_time": "2020-10-12T14:32:50.938677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=RandomForestClassifier(class_weight='balanced_subsample',\n",
       "                                              max_depth=16, n_estimators=200),\n",
       "             param_grid={'max_depth': [14], 'n_estimators': [270]},\n",
       "             scoring=make_scorer(f1_score, average=weighted))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters that are tuned for gridsearch\n",
    "param_grid = { \n",
    "    'n_estimators': [270],\n",
    "    'max_depth' : [14]\n",
    "}\n",
    "\n",
    "# Model initializer\n",
    "rfc=RandomForestClassifier(class_weight = 'balanced_subsample', n_estimators = 200,max_depth = 16)\n",
    "##rfc=RandomForestClassifier(class_weight = 'balanced', random_state=0)\n",
    "\n",
    "# Specific scoring method\n",
    "scorer = metrics.make_scorer(metrics.f1_score, average = 'weighted')\n",
    "# GridSearch\n",
    "rf_cv = GridSearchCV(estimator=rfc, param_grid=param_grid, scoring=scorer, cv= 3)\n",
    "# Fit train data\n",
    "rf_cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T14:33:10.785310Z",
     "iopub.status.busy": "2020-10-12T14:33:10.784482Z",
     "iopub.status.idle": "2020-10-12T14:33:10.791296Z",
     "shell.execute_reply": "2020-10-12T14:33:10.790620Z"
    },
    "papermill": {
     "duration": 0.030401,
     "end_time": "2020-10-12T14:33:10.791428",
     "exception": false,
     "start_time": "2020-10-12T14:33:10.761027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for training data: 0.5674948247064505 \n",
      "\n",
      "Best n_estimators: 270 \n",
      "\n",
      "Best max_depth: 14 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## View the accuracy score\n",
    "print('Best score for training data:', rf_cv.best_score_,\"\\n\") \n",
    "\n",
    "## View the best parameters for the model found using grid search\n",
    "print('Best n_estimators:',rf_cv.best_estimator_.n_estimators,\"\\n\") \n",
    "print('Best max_depth:',rf_cv.best_estimator_.max_depth,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T14:33:10.838169Z",
     "iopub.status.busy": "2020-10-12T14:33:10.837311Z",
     "iopub.status.idle": "2020-10-12T14:33:11.325897Z",
     "shell.execute_reply": "2020-10-12T14:33:11.326878Z"
    },
    "papermill": {
     "duration": 0.516841,
     "end_time": "2020-10-12T14:33:11.327119",
     "exception": false,
     "start_time": "2020-10-12T14:33:10.810278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for rf model GridSearchCV(cv=3,\n",
      "             estimator=RandomForestClassifier(class_weight='balanced_subsample',\n",
      "                                              max_depth=16, n_estimators=200),\n",
      "             param_grid={'max_depth': [14], 'n_estimators': [270]},\n",
      "             scoring=make_scorer(f1_score, average=weighted)):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.99      0.99       755\n",
      "           2       0.99      0.99      0.99      1597\n",
      "           3       0.97      1.00      0.98      1209\n",
      "           4       1.00      0.99      1.00      5996\n",
      "\n",
      "    accuracy                           0.99      9557\n",
      "   macro avg       0.99      0.99      0.99      9557\n",
      "weighted avg       0.99      0.99      0.99      9557\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict validate data and evaluate for validate data\n",
    "y_pred_validate = rf_cv.predict(x_train)\n",
    "print(\"Classification report for rf model %s:\\n%s\\n\"\n",
    "      % (rf_cv, metrics.classification_report(y_train, y_pred_validate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018532,
     "end_time": "2020-10-12T14:33:11.365701",
     "exception": false,
     "start_time": "2020-10-12T14:33:11.347169",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submit for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T14:33:11.414756Z",
     "iopub.status.busy": "2020-10-12T14:33:11.413980Z",
     "iopub.status.idle": "2020-10-12T14:33:21.817387Z",
     "shell.execute_reply": "2020-10-12T14:33:21.816655Z"
    },
    "papermill": {
     "duration": 10.432451,
     "end_time": "2020-10-12T14:33:21.817543",
     "exception": false,
     "start_time": "2020-10-12T14:33:11.385092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "# Read the test CSV Data\n",
    "path = '/kaggle/input/costa-rican-household-poverty-prediction/test.csv'\n",
    "test_data = pd.read_csv(path)\n",
    "test_data = applyFE(test_data)\n",
    "y_pred = rf_cv.predict(test_data)\n",
    "# Read submission file\n",
    "path = '/kaggle/input/costa-rican-household-poverty-prediction/sample_submission.csv'\n",
    "test = pd.read_csv(path)\n",
    "test['Target'] = y_pred\n",
    "test.to_csv(\"submission.csv\", index= False)\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.0187,
     "end_time": "2020-10-12T14:33:21.855733",
     "exception": false,
     "start_time": "2020-10-12T14:33:21.837033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 40.986409,
   "end_time": "2020-10-12T14:33:21.983970",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-12T14:32:40.997561",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
